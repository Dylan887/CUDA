This project, based on the original one, adds functionality for performance testing with Nsight Compute (NCU). It also enhances the robustness of related scripts and modifies some parts of the framework code (mainly dataset size and epochs) to improve model performance testing efficiency. Additionally, it includes improvements to LSTM-related functionality within the model.



### Overview

**Nsight Compute (NCU)** is an NVIDIA-provided GPU kernel-level performance analysis tool, focusing on the optimization of CUDA programs. It provides detailed performance data on computing resources, memory bandwidth, instruction scheduling, and more, suitable for analyzing bottlenecks in individual or multiple CUDA kernels. **Nsight Systems (NSYS)**, on the other hand, is a system-level performance analysis tool that examines the synergy of GPU, CPU, memory, and I/O. It uses timeline displays to give an overview of application performance. The two tools differ in scope and usage: NCU specializes in kernel-level optimization, ideal for CUDA developers seeking in-depth analyses; NSYS provides application-level performance overviews, suitable for identifying efficiency issues in CPU-GPU collaboration. In practical workflows, you can first use NSYS to identify performance bottlenecks and then use NCU for deeper GPU kernel optimization, thus thoroughly improving program performance.

### 1. Experimental Environment

```bash
Ubuntu 22.04.5 LTS
NVIDIA RTX A6000
cuda 12.4
nsys 2024.5.1
ncu 2024.3.2
docker 27.2.1
python 3.10.12
pytorch 2.5.1
```

### 2. Docker Launch Command

```bash
docker run --rm --gpus all --network host --shm-size=4g -it \
    --cap-add=SYS_ADMIN \
    -v /usr/local/cuda-12.4:/usr/local/cuda-12.4 \
    -v /usr/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu \
    -v /opt/nvidia/nsight-systems/2024.5.1:/opt/nvidia/nsight-systems/2024.5.1 \
    -v /opt/nvidia/nsight-compute/2024.3.2:/opt/nvidia/nsight-compute/2024.3.2 \
    -e PATH="/opt/nvidia/nsight-systems/2024.5.1/bin:/opt/nvidia/nsight-compute/2024.3.2/bin:/usr/local/cuda-12.4/bin:$PATH" \
    models_test:v2
```

Here, `cuda`, `nsys`, and `ncu` still use the toolkits from the host machine. The `--cap-add=SYS_ADMIN` option is to elevate permissions for `ncu` usage; without it, performance tests cannot be run.

### 3. Usage Guide

The project provides related commands as bash scripts located in `/workspace/command/`. The options `-nsys` and `-ncu` indicate scripts for performance testing using these two different tools. `start` executes performance tests for a single model, and `start-all` executes performance tests for all models. The `clean` script is used to remove files generated by performance tests. The usage examples are as follows:

**Single Model Testing Mode**: Take MobilenetV2 as an example.
First, navigate into the model's directory (where `train.py` and `inference.py` are located).

1. `start-ncu <arg>`: Use `ncu` for performance testing. `<arg>` can be `train`, `inference`, or `train inference` to indicate training, inference, or both training then inference. Alternatively, you can run `bash /workspace/command/start_ncu.sh <arg>`. For example: `start-ncu train`
2. `start-nsys <arg>`: Use `nsys` for performance testing. `<arg>` options are the same as above. Alternatively, run `bash /workspace/command/start_nsys.sh <arg>`.
3. `clean +y(Y)`: Deletes all files with `.csv`, `.pth`, `.sqlite`, `.nsys-rep`, and `.ncu-rep` suffixes in the current directory.

**Batch Testing Mode**
Make sure you are in the `/workspace/models/` directory (subdirectories contain the respective models):

1. `start-all-ncu`
2. `start-all-nsys`

Because there are many models, batch testing is not recommended. Also, NCU testing takes longer than NSYS. In the actual experiments, the command executed was:

```bash

ncu -o train --section LaunchStats --target-processes application-only --replay-mode kernel python train.py
```

The dataset for the model training was adjusted.
If you need to extend more functionality, please modify the corresponding scripts in `command` and adjust the model architecture or data to suit actual project requirements.

The related code has been uploaded at:
https://github.com/Dylan887/CUDA/tree/main/models_performance_test

### 4. Appendix: Explanation of NCU Commands

Some parameters may differ according to different versions. Refer to `ncu --help` for details.

```bash

ncu --set full --export train.ncu-rep --target-processes all --replay-mode application python train.py
```

1. `--set full`
   Collects a complete performance data set. This option enables all available sections and metrics in Nsight Compute, providing a comprehensive performance analysis of the target program.
2. `--export train.ncu-rep`
   Indicates exporting the performance report as `train.ncu-rep`. You can also use `-o train` instead.
3. `--target-processes all`
   `all` means capturing all processes related to the target program, including the main process and any spawned child processes.
4. `--target-processes` modes:

| Mode                 | Description                                                  |
| -------------------- | ------------------------------------------------------------ |
| **all**              | Captures all processes related to the target program, including the main and child processes. |
| **application-only** | Captures only processes related to the application.          |

1. `--replay-mode application` (Replay mode)

| Mode            | Description                                                  |
| --------------- | ------------------------------------------------------------ |
| **application** | The program runs fully, capturing performance data for all CUDA kernels, suitable for comprehensive analysis. |
| **kernel**      | Each CUDA kernel is replayed individually after the program finishes to gather more detailed performance metrics, possibly running multiple times. |

1. `python train.py`: The Python program to be executed.

**If you directly use the above command and collect all sections, it might take a very long time. For instance, when testing the training part of the MobilenetV2 model, an attempt that took nearly an hour still did not finish. In this case, you can choose a command that captures fewer sections, for example, focusing only on memory-related metrics:**

```
bashCopy codencu -o train -f --section "regex:MemoryWorkloadAnalysis(_Chart|_Tables)?"  \
--target-processes all --replay-mode application python train.py
```

Here:

* `-f` forces overwrite of existing output files.
* `--section "regex:MemoryWorkloadAnalysis(_Chart|_Tables)?"` matches `MemoryWorkloadAnalysis` followed optionally by `_Chart` or `_Tables`.

After generating the `train.ncu-rep` report, you can have NCU re-import it and print detailed information as a CSV file for storage:

```bash
ncu -i train.ncu-rep --page details --csv --log-file train.csv
```

In the following example, NCU profiles all sub-processes named `python` launched by the user's "command" on device 0, and only those kernels not starting with "nc":

```bash
ncu -o train -f --replay-mode application --target-processes all \
--section "regex:MemoryWorkloadAnalysis(_Chart|_Tables)?" \
--kernel-name "regex:^[^n][^c].*" --device 0 \
--target-processes-filter python train.py
```

------

**Explanation of Sections:**

| Identifier and Filename | Description                                                  |
| ----------------------- | ------------------------------------------------------------ |
| ComputeWorkloadAnalysis | Provides a detailed analysis of the Streaming Multiprocessors (SM) compute resources, including achieved Instructions Per Clock (IPC) and the utilization of each pipeline. High utilization pipelines might limit overall performance. |
| InstructionStats        | Statistics of the executed low-level assembly instructions (SASS). The instruction mix reveals the types and frequency of executed instructions. A narrow mix might cause dependency on a few pipelines, while others remain unused. Utilizing multiple pipelines allows hiding latencies and enables parallel execution. |
| LaunchStats             | Summarizes the kernel launch configuration (grid size, block division, GPU resource allocation). Choosing an efficient launch configuration can maximize device utilization. |
| MemoryWorkloadAnalysis  | A detailed analysis of GPU memory resources. When hardware units are fully utilized (Mem Busy), communication bandwidth is exhausted (Max Bandwidth), or memory instruction throughput is at maximum (Mem Pipes Busy), memory can become a bottleneck. The charts and tables help identify the exact memory system bottleneck. |
| NUMA Affinity           | Shows Non-Uniform Memory Access (NUMA) affinities based on compute and memory distances for all GPUs. |
| Nvlink                  | Provides a high-level summary of NVLink utilization, including total received and transmitted memory and overall peak link utilization. |
| Nvlink_Tables           | Detailed tables with properties for each NVLink.             |
| Nvlink_Topology         | An NVLink topology diagram showing logical connections and transmit/receive throughput. |
| Occupancy               | Occupancy is the ratio of active warps per multiprocessor to the maximum possible. It can also be seen as the percentage of the hardware’s ability to process warps that is actively in use. |
| PM Sampling             | A timeline view of periodically sampled metrics over the workload duration. Data is collected over multiple passes. |
| SchedulerStats          | Summarizes the activity of the schedulers issuing instructions. Each scheduler maintains a pool of warps and checks their state every cycle. |
| SourceCounters          | Provides source-level metrics, including branch efficiency and sampled warp stall reasons. |
| SpeedOfLight            | A high-level overview of the GPU’s compute and memory throughput, showing the percentage of the theoretical maximum that is utilized. |
| WarpStateStats          | Analyzes the states of all warps and the number of cycles they spend in each state during kernel execution. |

------

**References:**

1. https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#overhead
2. https://docs.nvidia.com/nsight-compute/ProfilingGuide/index.html#sections-and-rules
3. https://www.androsheep.win/post/ncu/
4. https://github.com/pytorch/data?tab=readme-ov-file#installation